<!doctype html><html class="theme-next use-motion theme-next-mist"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="stylesheet" type="text/css" href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5"><link rel="stylesheet" type="text/css" href="/css/main.css?v=0.4.5.1"><meta name="keywords" content="Python,Python爬虫,链家,"><link rel="alternate" href="/atom.xml" title="Redanula's Blog" type="application/atom+xml"><link rel="shorticon icon" type="image/x-icon" href="/favicon.ico?v=0.4.5.1"><meta name="description" content="业余时间做了个链家的爬虫，爬取数据写入sqlite，方便浏览和对比。具体参考了冰蓝大牛的博客http://lanbing510.info/2016/03/15/Lianjia-Spider.html?utm_source=tuicool&amp;amp;utm_medium=referral, 根据链家最新的web样式做了修改（2017-03）爬在售的二手房的数据。 链家对短时间内同一个IP的流量有监控，"><meta name="keywords" content="Python,Python爬虫,链家"><meta property="og:type" content="article"><meta property="og:title" content="Python链家爬虫"><meta property="og:url" content="http://yoursite.com/2017/03/21/Python链家爬虫/index.html"><meta property="og:site_name" content="Redanula&#39;s Blog"><meta property="og:description" content="业余时间做了个链家的爬虫，爬取数据写入sqlite，方便浏览和对比。具体参考了冰蓝大牛的博客http://lanbing510.info/2016/03/15/Lianjia-Spider.html?utm_source=tuicool&amp;amp;utm_medium=referral, 根据链家最新的web样式做了修改（2017-03）爬在售的二手房的数据。 链家对短时间内同一个IP的流量有监控，"><meta property="og:locale" content="zh-Hans"><meta property="og:image" content="http://yoursite.com/2017/03/21/Python链家爬虫/images/imgdata.png"><meta property="og:updated_time" content="2018-10-17T03:58:32.021Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Python链家爬虫"><meta name="twitter:description" content="业余时间做了个链家的爬虫，爬取数据写入sqlite，方便浏览和对比。具体参考了冰蓝大牛的博客http://lanbing510.info/2016/03/15/Lianjia-Spider.html?utm_source=tuicool&amp;amp;utm_medium=referral, 根据链家最新的web样式做了修改（2017-03）爬在售的二手房的数据。 链家对短时间内同一个IP的流量有监控，"><meta name="twitter:image" content="http://yoursite.com/2017/03/21/Python链家爬虫/images/imgdata.png"><script type="text/javascript" id="hexo.configuration">var CONFIG={scheme:"Mist",sidebar:"post"}</script><title> Python链家爬虫 | Redanula's Blog</title></head><body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans"><!--[if lte IE 8]><div style=' clear: both; height: 59px; padding:0 0 0 15px; position: relative;margin:0 auto;'> <a href="http://windows.microsoft.com/en-US/internet-explorer/products/ie/home?ocid=ie6_countdown_bannercode"><img src="http://7u2nvr.com1.z0.glb.clouddn.com/picouterie.jpg" border="0" height="42" width="820" alt="You are using an outdated browser. For a faster, safer browsing experience, upgrade for free today or use other browser ,like chrome firefox safari." style='margin-left:auto;margin-right:auto;display: block;'/></a></div><![endif]--><script type="text/javascript">var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="//hm.baidu.com/hm.js?cd0419a7cec497e5e5d0831c0c0d58c9";var c=document.getElementsByTagName("script")[0];c.parentNode.insertBefore(e,c)}()</script><div class="container one-column page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><h1 class="site-meta"><span class="logo-line-before"><i></i></span><a href="/" class="brand" rel="start"><span class="logo"><i class="icon-next-logo"></i></span> <span class="site-title">Redanula's Blog</span></a><span class="logo-line-after"><i></i></span></h1><div class="site-nav-toggle"> <button><span class="btn-bar"></span><span class="btn-bar"></span><span class="btn-bar"></span></button></div><nav class="site-nav"><ul id="menu" class="menu menu-left"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon icon-next-home"></i><br> 首页</a></li><li class="menu-item menu-item-archives"><a href="/archives" rel="section"><i class="menu-item-icon icon-next-archives"></i><br> 归档</a></li><li class="menu-item menu-item-tags"><a href="/tags" rel="section"><i class="menu-item-icon icon-next-tags"></i><br> 标签</a></li><li class="menu-item menu-item-guestbook"><a href="/guestbook" rel="section"><i class="menu-item-icon icon-next-guestbook"></i><br> 留言</a></li></ul><div class="site-search"><form class="site-search-form"> <input type="text" id="st-search-input" class="st-search-input st-default-search-input"></form><script type="text/javascript">!function(t,e,n,s,c,i,o){t.SwiftypeObject=c,t[c]=t[c]||function(){(t[c].q=t[c].q||[]).push(arguments)},i=e.createElement(n),o=e.getElementsByTagName(n)[0],i.async=1,i.src="//s.swiftypecdn.com/install/v2/st.js",o.parentNode.insertBefore(i,o)}(window,document,"script",0,"_st"),_st("install","nxUVom3vECYwEssxwyny","2.0.0")</script></div></nav></div></header><main id="main" class="main"><div class="main-inner"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><header class="post-header"><h1 class="post-title" itemprop="name headline"> Python链家爬虫</h1><div class="post-meta"> <span class="post-time">发表于 <time itemprop="dateCreated" datetime="2017-03-21T10:23:17+08:00" content="2017-03-21">2017-03-21</time></span> <span class="post-comments-count">&nbsp; | &nbsp;<a href="/2017/03/21/Python链家爬虫/#comments" itemprop="discussionUrl"><span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/03/21/Python链家爬虫/" itemprop="commentsCount"></span></a></span></div></header><div class="post-body"><span itemprop="articleBody"><p>业余时间做了个链家的爬虫，爬取数据写入sqlite，方便浏览和对比。<br>具体参考了冰蓝大牛的博客<a href="http://lanbing510.info/2016/03/15/Lianjia-Spider.html?utm_source=tuicool&amp;utm_medium=referral" target="_blank" rel="noopener">http://lanbing510.info/2016/03/15/Lianjia-Spider.html?utm_source=tuicool&amp;utm_medium=referral</a>, 根据链家最新的web样式做了修改（2017-03）爬在售的二手房的数据。</p><p>链家对短时间内同一个IP的流量有监控，所以如果用多线程去爬，太快可能会被要求输入验证码。试了以下用代理ip池去爬，因为可用的免费代理ip不多也不稳定，就放弃了。后面想数据爬的也不多，就加个延时模拟人为慢慢爬了，另外还有个问题可能是单位时间内Request太快可能解析不到数据，就把延时放在BeautifulSoup解析后面，并加了如果没有数据则重复5次请求的验证过程，才成功抓全数据：</p><pre><code><span class="tag">time</span>.<span class="function"><span class="title">sleep</span><span class="params">(np.random.rand()</span></span>*<span class="number">3</span>+<span class="number">3</span>)
</code></pre><p>这里贴出关键的匹配代码，代码好粗糙，仅供发参考：）</p><pre><code><span class="function"><span class="keyword">def</span> <span class="title">onsell_spider</span><span class="params">(mydb,url_page=<span class="string">u"http://gz.lianjia.com/ershoufang/pg1rs越秀/"</span>,area=<span class="string">u"越秀"</span>)</span>:</span>
    <span class="comment"># time.sleep(np.random.rand()*1)</span>
    <span class="keyword">print</span> url_page
    counts = <span class="number">0</span>
    trytime = <span class="number">0</span>
    <span class="keyword">while</span> counts==<span class="number">0</span> &amp; trytime&lt;=<span class="number">5</span>:
        <span class="keyword">try</span>:
            req = urllib2.Request(url_page,headers=hds[random.randint(<span class="number">0</span>,len(hds)-<span class="number">1</span>)])
            source_code = urllib2.urlopen(req,timeout=<span class="number">10</span>).read()
            plain_text=unicode(source_code)<span class="comment">#,errors='ignore')   </span>
            soup = BeautifulSoup(plain_text, <span class="string">"lxml"</span>)
        <span class="keyword">except</span> (urllib2.HTTPError, urllib2.URLError), e:
            <span class="keyword">print</span> e
            exception_write(<span class="string">'onsell_spider'</span>,url_page)
            <span class="keyword">return</span>
        <span class="keyword">except</span> Exception,e:
            <span class="keyword">print</span> e
            exception_write(<span class="string">'onsell_spider'</span>,url_page)
            <span class="keyword">return</span>
        time.sleep(np.random.rand()*<span class="number">3</span>+<span class="number">3</span>)
        cj_list=soup.findAll(<span class="string">'div'</span>,{<span class="string">'class'</span>:<span class="string">'info clear'</span>})

        <span class="keyword">print</span> len(cj_list)
        counts = len(cj_list)
        trytime = trytime + <span class="number">1</span>
        <span class="keyword">for</span> cj <span class="keyword">in</span> cj_list:
            info_dict={}
            href=cj.find(<span class="string">'a'</span>)
            <span class="keyword">if</span> <span class="keyword">not</span> href:
                <span class="keyword">continue</span>
            info_dict.update({<span class="string">u'链接'</span>:href.attrs[<span class="string">'href'</span>]})
            name=cj.find(<span class="string">'a'</span>).text
            info_dict.update({<span class="string">u'标题'</span>:name})

     <span class="comment">#href TEXT primary key UNIQUE, name TEXT, community TEXT, style TEXT, area TEXT, orientation TEXT,decoration TEXT,haslift TEXT,floor TEXT, year TEXT, bplace TEXT,splace TEXT, unit_price TEXT, total_price TEXT, subway TEXT, other TEXT</span>

            content=unicode(cj.find(<span class="string">'div'</span>,{<span class="string">'class'</span>:<span class="string">'houseInfo'</span>}).renderContents().strip())
            info=re.match(<span class="string">r"&lt;span .*&gt;&lt;/span&gt;&lt;a .*&gt;(.*)&lt;/a&gt;(.*)"</span>, content)

            <span class="comment"># print info</span>
            <span class="keyword">if</span> info:
                info=info.groups()
                info_dict.update({<span class="string">u'小区'</span>:info[<span class="number">0</span>]})

                str = info[<span class="number">1</span>].strip().split(<span class="string">'|'</span>)
                <span class="comment"># print str[1]</span>

                <span class="keyword">try</span>:
                    info_dict.update({<span class="string">u'户型'</span>:str[<span class="number">1</span>].strip()})
                <span class="keyword">except</span> Exception,e:
                    info_dict.update({<span class="string">u'户型'</span>:<span class="string">''</span>})
                <span class="keyword">try</span>:
                    info_dict.update({<span class="string">u'面积'</span>:str[<span class="number">2</span>].strip()})
                <span class="keyword">except</span> Exception,e:
                    info_dict.update({<span class="string">u'面积'</span>:<span class="string">''</span>})
                <span class="keyword">try</span>:
                    info_dict.update({<span class="string">u'朝向'</span>:str[<span class="number">3</span>].strip()})
                <span class="keyword">except</span> Exception,e:
                    info_dict.update({<span class="string">u'朝向'</span>:<span class="string">''</span>})
                <span class="keyword">try</span>:
                    info_dict.update({<span class="string">u'装修'</span>:str[<span class="number">4</span>].strip()})
                <span class="keyword">except</span> Exception,e:
                    info_dict.update({<span class="string">u'装修'</span>:<span class="string">''</span>})
                <span class="keyword">try</span>:
                    info_dict.update({<span class="string">u'有无电梯'</span>:str[<span class="number">5</span>].strip()})
                <span class="keyword">except</span> Exception,e:
                    info_dict.update({<span class="string">u'有无电梯'</span>:<span class="string">''</span>})

            content=unicode(cj.find(<span class="string">'div'</span>,{<span class="string">'class'</span>:<span class="string">'positionInfo'</span>}).renderContents().strip())
            info=re.match(<span class="string">r"&lt;span .*&gt;&lt;/span&gt;(.*)\)(.*)&lt;a .*&gt;(.*)&lt;/a&gt;"</span>, content)
            <span class="keyword">if</span> info:
                info=info.groups()
                <span class="comment"># print info</span>
                info_dict.update({<span class="string">u'楼层'</span>:info[<span class="number">0</span>]})
                info_dict.update({<span class="string">u'建造时间'</span>:info[<span class="number">1</span>]})
                info_dict.update({<span class="string">u'大区域'</span>:area})
                <span class="keyword">try</span>:
                    info_dict.update({<span class="string">u'小区域'</span>:info[<span class="number">2</span>]})
                <span class="keyword">except</span> Exception,e:
                    info_dict.update({<span class="string">u'小区域'</span>:info[<span class="number">2</span>]})


            content=cj.find(<span class="string">'div'</span>,{<span class="string">'class'</span>:<span class="string">'unitPrice'</span>}).find(<span class="string">'span'</span>).text
            <span class="keyword">if</span> content:
                info_dict.update({<span class="string">u'单价'</span>:content})
            content=cj.find(<span class="string">'div'</span>,{<span class="string">'class'</span>:<span class="string">'totalPrice'</span>}).find(<span class="string">'span'</span>).text
            <span class="keyword">if</span> content:
                info_dict.update({<span class="string">u'总价'</span>:content})

            content=cj.find(<span class="string">'span'</span>,{<span class="string">'class'</span>:<span class="string">'subway'</span>})
            <span class="comment"># print content</span>
            <span class="keyword">if</span> content:
                <span class="keyword">try</span>:
                    info_dict.update({<span class="string">u'地铁'</span>:content.text})
                <span class="keyword">except</span> Exception,e:
                    info_dict.update({<span class="string">u'地铁'</span>:<span class="string">''</span>})

            content=cj.find(<span class="string">'div'</span>,{<span class="string">'class'</span>:<span class="string">'followInfo'</span>}).text
            <span class="keyword">if</span>  content:
                info_dict.update({<span class="string">u'其他'</span>:content})

            command=sql_onsell_insert_command(info_dict)
            mydb.execute(command,<span class="number">1</span>)


<span class="function"><span class="keyword">def</span> <span class="title">do_onsell_spider</span><span class="params">(mydb,area=<span class="string">u"越秀"</span>)</span>:</span>

    url=<span class="string">u"http://gz.lianjia.com/ershoufang/pg%drs%s/"</span> % (<span class="number">1</span>,area)

    <span class="keyword">try</span>:
        req = urllib2.Request(url,headers=hds[random.randint(<span class="number">0</span>,len(hds)-<span class="number">1</span>)])
        source_code = urllib2.urlopen(req,timeout=<span class="number">10</span>).read()
        plain_text=unicode(source_code)<span class="comment">#,errors='ignore')   </span>
        soup = BeautifulSoup(plain_text, <span class="string">"lxml"</span>)
    <span class="keyword">except</span> (urllib2.HTTPError, urllib2.URLError), e:
        <span class="keyword">print</span> e
        exception_write(<span class="string">'do_onsell_spider'</span>,area)
        <span class="keyword">return</span>
    <span class="keyword">except</span> Exception,e:
        <span class="keyword">print</span> e
        exception_write(<span class="string">'do_onsell_spider'</span>,area)
        <span class="keyword">return</span>

    time.sleep(np.random.rand()*<span class="number">1</span>+<span class="number">1</span>)
    content=soup.find(<span class="string">'div'</span>,{<span class="string">'class'</span>:<span class="string">'page-box house-lst-page-box'</span>})
    <span class="comment"># print soup</span>

    <span class="keyword">if</span> content:
        d=<span class="string">"d="</span>+content.get(<span class="string">'page-data'</span>)
        exec(d)
        total_pages=d[<span class="string">'totalPage'</span>]

    <span class="keyword">print</span> total_pages

    <span class="keyword">for</span> i <span class="keyword">in</span> range(total_pages):
        time.sleep(np.random.rand()*<span class="number">1</span>)
        url_page=<span class="string">u"http://gz.lianjia.com/ershoufang/pg%drs%s/"</span> % (i+<span class="number">1</span>,area)
        onsell_spider(mydb,url_page,area)
</code></pre><p>对BeautifulSoup的方法还不太熟悉，用的都是简单粗暴的方法，后续再去细看了。</p><p>爬下来的数据：<br> <img src="images/imgdata.png" alt="imgdata"></p></span></div><footer class="post-footer"><div class="post-tags"> <a href="/tags/Python/" rel="tag">#Python</a> <a href="/tags/Python爬虫/" rel="tag">#Python爬虫</a> <a href="/tags/链家/" rel="tag">#链家</a></div><div class="post-nav"><div class="post-nav-prev post-nav-item"> <a href="/2017/07/30/iOS-Tips-NSDictionary-NSArray-快捷计算函数/" rel="prev">iOS Tips--NSDictionary和NSArray 快捷计算函数</a></div><div class="post-nav-next post-nav-item"> <a href="/2017/03/13/Python高德爬虫/" rel="next">Python高德爬虫</a></div></div></footer></article><div class="post-spread"></div></div></div><div class="comments" id="comments"><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span><span class="sidebar-toggle-line sidebar-toggle-line-middle"></span><span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap"> 文章目录</li><li class="sidebar-nav-overview" data-target="site-overview"> 站点概览</li></ul><section class="site-overview"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"> <img class="site-author-image" src="/images/avatar.jpg" alt="Redanula" itemprop="image"><p class="site-author-name" itemprop="name">Redanula</p></div><p class="site-description motion-element" itemprop="description"></p><nav class="site-state motion-element"><div class="site-state-item site-state-posts"> <a href="/archives"><span class="site-state-item-count">16</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"> <span class="site-state-item-count">0</span> <span class="site-state-item-name">分类</span></div><div class="site-state-item site-state-tags"> <a href="/tags"><span class="site-state-item-count">27</span> <span class="site-state-item-name">标签</span></a></div></nav><div class="feed-link motion-element"><a href="/atom.xml" rel="alternate"><i class="menu-item-icon icon-next-feed"></i> RSS</a></div><div class="links-of-author motion-element"> <span class="links-of-author-item"><a href="https://github.com/redanula" target="_blank">github</a></span> <span class="links-of-author-item"><a href="http://weibo.com/redanula" target="_blank">weibo</a></span></div><div class="links-of-author motion-element"></div></section><section class="post-toc-wrap sidebar-panel-active"><div class="post-toc-indicator-top post-toc-indicator"></div><div class="post-toc"><p class="post-toc-empty">此文章未包含目录</p></div><div class="post-toc-indicator-bottom post-toc-indicator"></div></section></div></aside></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright"> &copy; &nbsp; <span itemprop="copyrightYear">2018</span><span class="with-love"><i class="icon-next-heart"></i></span> <span class="author" itemprop="copyrightHolder">Redanula</span></div><div class="powered-by"> 由 <a class="theme-link" href="http://hexo.io">Hexo</a> 强力驱动</div><div class="theme-info"> 主题 - <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a></div></div></footer><div class="back-to-top"></div></div><script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script><script type="text/javascript">var disqus_shortname="redanula",disqus_identifier="2017/03/21/Python链家爬虫/",disqus_title="Python链家爬虫",disqus_url="http://yoursite.com/2017/03/21/Python链家爬虫/";function run_disqus_script(s){var t=document.createElement("script");t.type="text/javascript",t.async=!0,t.src="//"+disqus_shortname+".disqus.com/"+s,(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(t)}run_disqus_script("count.js"),run_disqus_script("embed.js")</script><script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js"></script><script type="text/javascript" src="/js/fancy-box.js?v=0.4.5.1"></script><script type="text/javascript" src="/js/helpers.js?v=0.4.5.1"></script><script type="text/javascript" src="/vendors/velocity/velocity.min.js"></script><script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js"></script><script type="text/javascript" src="/js/motion_global.js?v=0.4.5.1" id="motion.global"></script><script type="text/javascript" src="/js/nav-toggle.js?v=0.4.5.1"></script><script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script><script type="text/javascript" src="/js/bootstrap.scrollspy.js?v=0.4.5.1" id="bootstrap.scrollspy.custom"></script><script type="text/javascript" id="sidebar.toc.highlight">$(document).ready(function(){var t=".post-toc",i=$(t),o=".active-current";function e(){$(t+" "+o).removeClass(o.substring(1))}function n(){var o;o=$(".sidebar").height()-i.position().top-$(".post-toc-indicator-bottom").height(),i.css("height",o),s()}function s(){c(".post-toc-indicator-top",0<i.scrollTop()?"show":"hide"),c(".post-toc-indicator-bottom",i.scrollTop()>=i.find("ol").height()-i.height()?"hide":"show")}function c(o,t){var i=$(o),e="show"===t?.4:0;i.velocity?i.velocity("stop").velocity({opacity:e},{duration:100}):i.stop().animate({opacity:e},100)}i.on("activate.bs.scrollspy",function(){var o=$(t+" .active").last();e(),o.addClass("active-current"),i[0].scrollTop=o.position().top}).on("clear.bs.scrollspy",function(){e()}),$(document).on("sidebar.motion.complete",function(){n()}),$("body").scrollspy({target:t}),$(window).on("resize",function(){$(".sidebar").hasClass("sidebar-active")&&n()}),i.on("mousewheel DOMMouseScroll",function(o){var t=o.originalEvent,i=t.wheelDelta||-t.detail;this.scrollTop+=30*(i<0?1:-1),o.preventDefault(),s()})})</script><script type="text/javascript" id="sidebar.nav">$(document).ready(function(){var o=$("html"),s=200,n=$.isFunction(o.velocity);$(".sidebar-nav li").on("click",function(){var t=$(this),i="sidebar-nav-active",a="sidebar-panel-active";if(!t.hasClass(i)){var o=$("."+a),e=$("."+t.data("target"));n?o.velocity("transition.slideUpOut",s,function(){e.velocity("stop").velocity("transition.slideDownIn",s).addClass(a)}):o.animate({opacity:0},s,function(){o.hide(),e.stop().css({opacity:0,display:"block"}).animate({opacity:1},s,function(){o.removeClass(a),e.addClass(a)})}),t.siblings().removeClass(i),t.addClass(i)}}),$(".post-toc a").on("click",function(t){t.preventDefault();var i=escapeSelector(this.getAttribute("href")),a=$(i).offset().top;n?o.velocity("stop").velocity("scroll",{offset:a+"px",mobileHA:!1}):$("html, body").stop().animate({scrollTop:a},500)});var t=$(".post-toc-content");isDesktop()&&"post"===CONFIG.sidebar&&0<t.length&&0<t.html().trim().length&&displaySidebar()})</script><script type="text/javascript">$(document).ready(function(){"always"===CONFIG.sidebar&&displaySidebar(),isMobile()&&FastClick.attach(document.body)})</script><script type="text/javascript" src="/js/lazyload.js"></script><script type="text/javascript">$(function(){$("#posts").find("img").lazyload({placeholder:"/images/loading.gif",effect:"fadeIn"})})</script><script type="text/javascript" color="176,196,222" opacity="0.7" zindex="-2" count="70" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script><script type="text/javascript" src="/js/love.js"></script><script src="/live2dw/lib/L2Dwidget.min.js?0c58a1486de42ac6cc1c59c7d98ae887"></script><script>L2Dwidget.init({pluginRootPath:"live2dw/",pluginJsPath:"lib/",pluginModelPath:"assets/",tagMode:!1,log:!1,model:{jsonPath:"/live2dw/assets/hijiki.model.json"},display:{position:"right",width:100,height:200},react:{opacityDefault:1,opacityOnHover:.2},mobile:{show:!1,scale:.5}})</script></body></html>